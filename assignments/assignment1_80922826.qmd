---
title: "Assignment 1"
author: "Eryk Halicki (80922826)"
date: last-modified
format:
  html:
    embed-resources: true
    df-print: tibble
    html-math-method: mathml
execute:
  echo: true
---

```{r, echo=FALSE, warning=FALSE,message=FALSE}
library(car)
```

```{r}
obesity <- read.csv('/Users/erykhalicki/Documents/School/UBC/year3/DATA311/datasets/ObesityDataSet_raw_and_data_sinthetic.csv')


# Binary columns (yes/no)
obesity[c("family_history_with_overweight", "FAVC", "SMOKE", "SCC")] <- 
  lapply(obesity[c("family_history_with_overweight", "FAVC", "SMOKE", "SCC")], factor)

# Unordered categorical columns
obesity[c("Gender", "MTRANS")] <- 
  lapply(obesity[c("Gender", "MTRANS")], factor)

# Ordered categorical, binning continuous values
obesity$FCVC <- cut(obesity$FCVC, 
                    breaks = c(0, 1.5, 2.5, 3),
                    labels = c("Never", "Sometimes", "Always"),
                    include.lowest = TRUE,
                    ordered_result = TRUE)

obesity$NCP <- cut(obesity$NCP, 
                   breaks = c(0, 1.5, 2.5, 4),
                   labels = c("Between 1 and 2", "Three", "More than three"),
                   include.lowest = TRUE,
                   ordered_result = TRUE)

obesity$CH2O <- cut(obesity$CH2O,
                    breaks = c(0, 1.5, 2.5, 3),
                    labels = c("Less than a liter", "Between 1 and 2 L", "More than 2 L"),
                    include.lowest = TRUE,
                    ordered_result = TRUE)

obesity$FAF <- cut(obesity$FAF,
                   breaks = c(0, 0.5, 1.5, 2.5, 3),
                   labels = c("I do not have", "1 or 2 days", "2 or 4 days", "4 or 5 days"),
                   include.lowest = TRUE,
                   ordered_result = TRUE)

obesity$TUE <- cut(obesity$TUE,
                   breaks = c(0, 1, 1.5, 2),
                   labels = c("0–2 hours", "3–5 hours", "More than 5 hours"),
                   include.lowest = TRUE,
                   ordered_result = TRUE)

# CAEC and CALC are already categorical (text)
obesity$CAEC <- factor(obesity$CAEC,
                       levels = c("no", "Sometimes", "Frequently", "Always"),
                       ordered = TRUE)

obesity$CALC <- factor(obesity$CALC,
                       levels = c("no", "Sometimes", "Frequently", "Always"),
                       ordered = TRUE)

obesity$NObeyesdad <- factor(obesity$NObeyesdad,
                             levels = c("Insufficient_Weight", "Normal_Weight",
                                       "Overweight_Level_I", "Overweight_Level_II",
                                       "Obesity_Type_I", "Obesity_Type_II",
                                       "Obesity_Type_III"),
                             ordered = TRUE)
var_info <- data.frame(
  Variable = colnames(obesity),
  Type = sapply(obesity, function(x) class(x)[1]), # rename
  Description = c(
    "The gender of the participant",
    "Age of participant (years)",
    "Height (m)",
    "Weight (kg)",
    "Has a family member suffered or suffers from overweight?",
    "Do you eat high caloric food frequently?",
    "Do you usually eat vegetables in your meals?",
    "How many main meals do you have daily?",
    "Do you eat any food between meals?",
    "Do you smoke?",
    "How much water do you drink daily?",
    "Do you monitor the calories you eat daily?",
    "How often do you have physical activity?",
    "How much time do you use technological devices such as cell phone, videogames, television, computer and others? (Hours per week)",
    "How often do you drink alcohol?",
    "Which transportation do you usually use?",
    "Obesity level"
  )
)
```

This dataset contains data used to estimate the obesity levels in individuals from Mexico, Peru, and Columbia. The data is 77% synthetic and 23% was collected directly from users through a web platform. The dataset is sourced from https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition, and has `{r} nrow(obesity)` rows and `{r} ncol(obesity)` variables. More detailed versions of the variable desciptions are available at https://doi.org/10.1016/j.dib.2019.104344.

```{r} 
var_info

obesity
```

There are `r sum(is.na(obesity))` rows with missing values, nothing needs to be removed.

There are also `r sum(duplicated(obesity))` duplicated rows, but I dont believe we should remove them. Since there are no uniquely identifying features in the dataset (like name or a participant ID), it is entirely possible for the duplicates to be different individuals with the same responses. If we were to remove them, we could be skewing the data away from what was actually collected. 

```{r}
#| label: fig-scatter
#| fig-cap: "BMI vs Age scatterplot"
obesity$BMI <- obesity$Weight / (obesity$Height*obesity$Height)

plot(obesity$Age, obesity$BMI, xlab = 'Age', ylab = 'BMI', main = 'BMI vs Age')
```

As can be seen in @fig-scatter, the relationship between BMI and Age in the obesity dataset seems to be weakly positive, however there is a lot of variability in the data, especially at lower ages (~18-25).

I do not beleive that a linear model is appropriate for capturing the relationship between Age and BMI. Firstly, the data does not appear linearly correlated, since the weak positive relationship appears to become negative after age ~40. Furthermore, the data does not appear homoscedastic, since it becomes much tighter as Age increases (I.E. Funnel shaped).

```{r}
#| label: fig-boxplots
#| fig-cap: 
#|   - "BMI by Family History of Overweight"
#|   - "BMI by High Caloric Food Consumption"
#|   - "BMI by Smoking Status"
#|   - "BMI by Calorie Monitoring"
#|   - "BMI by Transportation Method"
#|   - "BMI by Obesity Level"
#|   - "BMI by Vegetable Consumption"
#|   - "BMI by Number of Main Meals"
#|   - "BMI by Eating Between Meals"
#|   - "BMI by Water Consumption"
#|   - "BMI by Physical Activity Frequency"
#|   - "BMI by Technology Use"
#|   - "BMI by Alcohol Consumption"

#unordered
boxplot(BMI ~ family_history_with_overweight, data = obesity)
boxplot(BMI ~ FAVC, data = obesity)
boxplot(BMI ~ SMOKE, data = obesity)
boxplot(BMI ~ SCC, data = obesity)
boxplot(BMI ~ MTRANS, data = obesity, cex.axis=0.8)
boxplot(BMI ~ NObeyesdad, data = obesity, cex.axis=0.45)

#ordered
boxplot(BMI ~ FCVC, data=obesity)
boxplot(BMI ~ NCP, data=obesity)
boxplot(BMI ~ CAEC, data=obesity)
boxplot(BMI ~ CH2O, data=obesity)
boxplot(BMI ~ FAF, data=obesity)
boxplot(BMI ~ TUE, data=obesity)
boxplot(BMI ~ CALC, data=obesity)
```

Although many of the boxplots show a relationship between BMI and their repsective category, BMI and family history of overweightness stands out to me. As can be seen in @fig-boxplots-1, there is a large difference between the mean of the two categories; participants without a family history of overweightness had a mean BMI of ~21, whereas participants with a family history of overweightness had a mean ~32. Furthermore, the 25th percentile of the "yes" category is higher than the 75th percetile of the "no" category. As such, I believe family history of overweightness is predictive of BMI, with respondants in the "yes" category having higher BMI's than those in the "no" category.

```{r}
set.seed(80922826)

train_indices <- sample(1:nrow(obesity), size= 0.7*nrow(obesity))

training_set <- obesity[train_indices, ]
testing_set <- obesity[-train_indices, ]
```

The training and testing sets have `r nrow(training_set)` and `r nrow(testing_set)` rows, respectively.

```{r}
bmi_age_linear_model <- lm(BMI ~ Age, training_set)
summary(bmi_age_linear_model)
bmi_age_linear_coeffs <- coef(bmi_age_linear_model)
```

As per the summary above, the estimated regression equation is BMI = `r  bmi_age_linear_coeffs[1]` + Age x `r bmi_age_linear_coeffs[2]`

The slope of the equation can interpreted as the effect a one unit change in Age has on the expected BMI. I.E. for an increase of one year in age, the model predicts a `r bmi_age_linear_coeffs[2]` increase in BMI.

```{r}
bmi_multi_linear_model <- lm(BMI ~ . - BMI - Weight - Height - NObeyesdad, data = training_set)
vif(bmi_multi_linear_model)
```

As can be seen in the output of the vif function, the GVIF^(1/(2*Df)) column (which from what I understand is like VIF, but for more types of variables), only has values very close to 1. This indicates that there is no evidence of probelmatic multicollinearity in the obesity dataset. This makes sense, since we removed the most correlated variables (weight, height, and obesity level), and the remaining variables are fairly independant from each other.

```{r}
bmi_multi_linear_model_2 <- lm(BMI ~ Age + Gender + family_history_with_overweight, data = training_set)
summary(bmi_multi_linear_model_2)
```

According to the output of the summary function, All 3 variables included in the above model (Age, Gender, and family history) have a statistically signficant relationship with BMI. 

```{r}
bmi_multi_linear_model_3 <- lm(BMI ~ Age + Gender + family_history_with_overweight + FAF, data = training_set)
summary(bmi_multi_linear_model_3)
bmi_multi_linear_model_3_coef <- coef(bmi_multi_linear_model_3)
```

The predictor I included is the ordered categorical variable FAF (frequency of physical activity). From what I understand, ordered categorical variables get seperated into multiple polynomial equations when they get included in a linear model, so we have FAF.L, FAF.Q and FAF.C, with L = linear component, Q = quadratic component, C = cubic component. 

From the p values of these 3 components, we can see that L is the most statistically signficant (p ~= 0), meaning that there is a signficant linear relationship between BMI and FAF, with one unit increase in FAF resulting in a `r bmi_multi_linear_model_3_coef[5][1]` change in BMI. 

However, there is also a quadratic component; FAF.Q. This component is also statistically significant, showing that the relationship between BMI and FAF is not strictly linear, I.E. the rate of change of BMI changes at different level of FAF. There is also FAF.C for the cubic component, but it does not appear statistically significant.

```{r}
bmi_age_gender_linear_model <- lm(BMI ~ Age + Gender, data = training_set)
summary(bmi_age_gender_linear_model)
age_gender_linear_coef <- coef(bmi_age_gender_linear_model)
```

According to the above model using age and gender,
$$
\text{BMI} = 
\begin{cases}
`r age_gender_linear_coef[1]` + `r age_gender_linear_coef[2]` \times \text{Age} & \text{if female} \\
`r age_gender_linear_coef[1]+age_gender_linear_coef[3]` + `r age_gender_linear_coef[2]` \times \text{Age} & \text{if male}
\end{cases}
$$

```{r}
bmi_age_gender_interaction_linear_model <- lm(BMI ~ Age + Gender + Age*Gender, data = training_set)
summary(bmi_age_gender_interaction_linear_model)
age_gender_interaction_linear_coef <- coef(bmi_age_gender_interaction_linear_model)
```

According to the above model using age, gender, and the interaction term Age*Gender,
$$
\text{BMI} = 
\begin{cases}
`r age_gender_interaction_linear_coef[1]` + `r age_gender_interaction_linear_coef[2]` \times \text{Age} & \text{if female} \\
`r age_gender_interaction_linear_coef[1]+age_gender_interaction_linear_coef[3]` + `r age_gender_interaction_linear_coef[2] + age_gender_interaction_linear_coef[4]` \times \text{Age} & \text{if male}
\end{cases}
$$

The p value of the Age*Gender term appears to be statistically significant, with p value ~= 0. This implies that in our model, Age has a different effect based on the gender we are trying to predict. I.E. the slope of Age is `r age_gender_interaction_linear_coef[4][1]` greater for males than females.

```{r}
plot(obesity$Age, obesity$BMI, xlab = 'Age', ylab = 'BMI')

abline(a = age_gender_interaction_linear_coef[1],
b = age_gender_interaction_linear_coef[2], 
col = "red", 
lwd=3)

abline(a = age_gender_interaction_linear_coef[1]+age_gender_interaction_linear_coef[3],
b = age_gender_interaction_linear_coef[2]+age_gender_interaction_linear_coef[4], col = "blue",
lwd=3)

legend("topleft", 
       legend = c("Female", "Male"), 
       col = c("red", "blue"), 
       pch = 16, lwd = 2)

female_38_year_old <- data.frame(
  Age = 38,
  Gender = "Female"
)

female_38_year_old_prediction <- predict(bmi_age_gender_interaction_linear_model, newdata = female_38_year_old)
```

The expected BMI of a 38 year old Female using the Age and BMI interaction model is `r female_38_year_old_prediction`.

To verify, the expected value based on the equation from earlier is 

$$ 
`r age_gender_interaction_linear_coef[1]` + `r age_gender_interaction_linear_coef[2]` \times \text{Age}  \text{ if female}
$$

Which for a 38 year old female is: $`r age_gender_interaction_linear_coef[1]` + `r age_gender_interaction_linear_coef[2]` \times 38 = `r age_gender_interaction_linear_coef[1]+ age_gender_interaction_linear_coef[2]*38`$

```{r}
models <- list(
  "Age only" = bmi_age_linear_model,
  "Age + Gender + Family History" = bmi_multi_linear_model_2,
  "Age + Gender + Family History + FAF" = bmi_multi_linear_model_3,
  "Age + Gender" = bmi_age_gender_linear_model,
  "Age + Gender + Interaction" = bmi_age_gender_interaction_linear_model
)

results <- data.frame(
  Model = names(models),
  Adj_R2 = numeric(length(models)),
  Train_MSE = numeric(length(models)),
  Test_MSE = numeric(length(models))
)

for(i in 1:length(models)) {
  model <- models[[i]]
  
  # Adjusted R2
  results$Adj_R2[i] <- summary(model)$adj.r.squared
  
  # Training MSE
  train_pred <- predict(model)
  results$Train_MSE[i] <- mean((training_set$BMI - train_pred)^2)
  
  # Test MSE
  test_pred <- predict(model, newdata = testing_set)
  results$Test_MSE[i] <- mean((testing_set$BMI - test_pred)^2)
}

results
```

I beleive the best model overall is the Age + Gender + Family History + FAF model. Its adjusted R^2 is greater than all the other models, and its train and test MSE are the lowest of all the models. 

```{r}
#| label: fig-bmi-diagnostics
#| fig-cap: "Diagnostic plots for BMI linear regression model"
#| fig-subcap:
#|   - "Residuals vs Fitted"
#|   - "Normal Q-Q"
#|   - "Scale-Location"
#|   - "Residuals vs Leverage"
#| layout-ncol: 2

plot(bmi_multi_linear_model_3)
```

In @fig-bmi-diagnostics-1 we can see that there is a non-constant variance between the fitted values and the residuals. There appears to be a funnel shape with variance increasing for higher BMI's, meaning that the model assumption of homoscedasticity is not met. Additionally, the red smoothed line shows a slight downward trend, suggesting mild non-linearity in the relationship. Overall, linearlity and homoscedasticity.

In @fig-bmi-diagnostics-2, we can see that there are deviations on the high and low ends of the diagonal. This suggests the some presence of outliers or that the underlying error distribution is not perfectly Gaussian, which violates the normality assumption of linear regression. However, most residuals do follow the diagonal, so most of the dataset is fairly normal.

The indpendance assumption is likely met since the dataset consists of cross-sectional observations from different individuals. The lack of systematic patterns in the residual plot further supports independence.

## Bias Variance Tradeoff
As we increase the amount of features used in our linear model, both adjusted R^2 and MSE improved. This indicates reduced bias, as the model better captures the underlying relationships in the training data. However, we can also expect that the models with more features have increased variance, since each variable used introduces a new source of model uncertainty, and makes the model more sensitive to the specific sample. 

This illustrates the bias-variance tradeoff. While added complexity reduces systematic error (bias), it increases the model's sensitivity to sampling variation (variance), potentially reducing generalizability to new data.


